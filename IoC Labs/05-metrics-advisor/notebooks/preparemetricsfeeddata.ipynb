{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will guide you through a list of steps needed to prepare a time series-based dataset containing JSON files to be fed into the Metrics Advisor workspace. Each JSON file will contain daily data representing the count of COVID positive cases by age group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the requires libraries and namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os, shutil\n",
    "import math\n",
    "import timeit\n",
    "from io import StringIO\n",
    "import re\n",
    "import urllib.request, json\n",
    "\n",
    "print(\"pandas version: {} numpy version: {}\".format(pd.__version__, np.__version__))\n",
    "\n",
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "# Check core SDK version number\n",
    "print(\"azureml SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the `<BLOBSTORAGE_ACCOUNT_NAME>` and `<BLOBSTORAGE_ACCOUNT_KEY>` values below with the values you have noted down on a previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide values for the existing blob storage account name and key\n",
    "blob_account_name = \"<BLOBSTORAGE_ACCOUNT_NAME>\"\n",
    "blob_account_key = \"<BLOBSTORAGE_ACCOUNT_KEY>\"\n",
    "blob_datastore_name='covid_datastore' # Name of the datastore to workspace\n",
    "container_name = \"jsonmetrics\" # Name of Azure blob container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Azure Machine Learning workspace and register the `covid_datastore` container in the workspace. This is the place where the input data for Metrics Advisor will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "#register the datastore where the Metrics Advisor data feed will be generated\n",
    "blob_datastore = Datastore.register_azure_blob_container(\n",
    "    workspace=ws, \n",
    "    datastore_name=blob_datastore_name, \n",
    "    container_name=container_name, \n",
    "    account_name=blob_account_name,\n",
    "    account_key=blob_account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the COVID-19 case surveillance dataset.\n",
    "\n",
    "Inspect the first 10 rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://solliancepublicdata.blob.core.windows.net/ai-in-a-day/shared/' +\n",
    "    'COVID19_Case_Surveillance_Data/COVID-19_Case_Surveillance_Public_Use_Data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the timestamp column to match the format required by the Metrics Advisor ingestion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cdc_report_dt']=pd.to_datetime(df['cdc_report_dt']) + (pd.to_timedelta(13, unit='M'))\n",
    "df['datekey'] =  pd.to_datetime(df['cdc_report_dt']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group data by date, age group, and hospitalization status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgroup = df.groupby(['datekey','age_group','hosp_yn']).size().to_frame()\n",
    "dfgroup.rename(columns={0: 'count'}, inplace=True)\n",
    "dfgroup.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index hierarchical index resulting from the group by process to flatten the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfflat = dfgroup.reset_index()\n",
    "dfflat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of dates for which data is available in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df['datekey'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the daily JSON files to be ingested by Metrics Advisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('covid_age_hosp'):\n",
    "    shutil.rmtree('covid_age_hosp')\n",
    "    \n",
    "os.mkdir('covid_age_hosp')\n",
    "\n",
    "for row in dates:\n",
    "    print(row)\n",
    "    is_date = dfflat['datekey']==row\n",
    "    df_date = dfflat[is_date]\n",
    "    resultJSON = df_date.to_json(orient='records', date_format='%Y-%m-%d')\n",
    "    filename_processed_json =  f'covid_age_hosp/{row}.json'\n",
    "    with open(filename_processed_json, 'w') as f:\n",
    "        f.write(resultJSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the local folder containing the generated JSON files to the blob storage container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore.upload('./covid_age_hosp', \n",
    "                 target_path = '', \n",
    "                 overwrite = True, \n",
    "                 show_progress = True)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
